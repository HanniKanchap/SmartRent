name: Update Rental Data

on:
  schedule:
    - cron: '0 21 * * 2'  # every Tuesday at 3 AM IST (UTC+5:30 = 21:00 UTC Monday)
  workflow_dispatch:

jobs:
  run-pipeline:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt

    - name: Register Jupyter kernel
      run: |
        python -m ipykernel install --user --name python3 --display-name "Python 3"

    - name: Run OLX scraping script
      run: |
        python Scraping/olx_scraping.py

    - name: Run cleaning notebook on updated data
      run: |
        jupyter nbconvert --to notebook --execute data_cleaning/data_cleaning.ipynb \
          --inplace \
          --ExecutePreprocessor.kernel_name=python3 \
          --ExecutePreprocessor.timeout=600

    - name: Commit updated data files
      run: |
        git config --global user.name "Hanni"
        git config --global user.email "hannikanchap11@gmail.com"
        git add scraped_olx_data.csv
        git add data/cleaned_data.csv
        git commit -m "Auto-update scraped and cleaned rental data"
        git push
      continue-on-error: true

    - name: Upload executed notebook for inspection
      uses: actions/upload-artifact@v3
      with:
        name: cleaned-notebook
        path: data_cleaning/data_cleaning.ipynb
